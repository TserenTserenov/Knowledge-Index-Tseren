# Общаюсь с LLM: какие навыки главные?

**Категория:** Черновики|Церен Церенов (черновики)

**Дата:** 2025-08-18

**URL:** http://systemsworld.club/t/obshhayus-s-llm-kakie-navyki-glavnye/29735/1

---

Взаимодействие с языковой моделью типа ChatGPT особенно продуктивно тогда, когда мы рассматриваем её не как «всемогущий интеллект», а как искусственного ассистента, поведение которого определяется тем мировоззрением, которое мы задаём в диалоге. В этом смысле модель — не источник готовой мудрости, а зеркало нашей собственной понятийной структуры: она подстраивается под уровень общения, который мы демонстрируем, воспроизводит используемые нами термины, логику, критерии качества и стили доказательства. Если говорить с ней на бытовом языке, мы и получаем бытовой результат; если вводим строгие понятия и требуем операционализируемые формы ответа, модель выстраивает поведение в рамках заданной дисциплины.
Продукты типа ChatGPT — это система, участвующая во внешнем для неё процессе диалога. Внешний для нее окружение задаём мы: формируем контекст, фиксируем границы обсуждения, ставим в роль и даже как-то влияем на ожидаемый эффект. Отсюда вытекает ключевой тезис: ответственность за качество результата лежит на стороне собеседника-человека, потому что именно он определяет, в какой «картине мира» будет работать ассистент. Практически это означает необходимость согласованной онтологии общения — общего языка типов объектов и отношений между ними, достаточного для постановки задачи без двусмысленностей.
В качестве такого языка особенно удобен системный: он позволяет различать категории, которые в повседневной речи сливаются и порождают ошибки. Система — это материальный объект, выполняющий функцию в заданном контексте; процесс — изменение состояний систем во времени; роль — функциональное поведение системы в конкретной ситуации; метод — описание способа достижения результата; продукт — оформленный артефакт деятельности. Разведение этих понятий устраняет логическую путаницу: мы не «создаём процесс», мы создаём систему, которая будет корректно участвовать в процессе; мы не «просим стараться», мы задаём роль и критерии её исполнения; мы не «обсуждаем примерно», мы работаем с продуктом, к которому предъявим проверяемые требования.
Почему это критично именно для общения с ЛЛМ? Потому что модель статистически продолжает нашу мысль: она подбирает следующий текст, согласованный с образцами, которые мы ей предоставили. Если образцом является расплывчатый словарь мотиваций, бытовых метафор и неразличённых категорий, то именно это и станет нормой дальнейшего вывода. Если же образцом становится дисциплина ролей, строгие определения, явные допущения и соглашения о формате результата, модель «перестраивает мировоззрение» под эту норму и начинает поддерживать соответствующие ходы рассуждения. В диалоге с математиком нельзя оставаться в пространстве разговорных интонаций — там требуется язык определений, лемм и критериев. Ровно так же при обсуждении продукта, сложной системы или траекторий саморазвития необходимо пользоваться языком функций, ограничений, интерфейсов, ролей и рабочих продуктов. Это не вопрос вкуса; это условие корректности.
Следует учитывать и симметрию ответственности. Относясь к ассистенту как к коллеге, мы допускаем возможность ошибок, пробелов знания и неверных выводов — так же, как в работе с человеком. Поэтому уместны требования к прозрачности: отмечать, где сделано допущение, на чём держится вывод, какие альтернативные объяснения существуют и как меняется уверенность при изменении исходных данных. Такая «политика доказательств» не является украшением текста — она формирует воспроизводимую практику мышления, органичную для совместной работы.
Отдельно стоит подчеркнуть значение ролей. Роль — не часть системы, а маска её функционального поведения в контексте. Когда ассистент «становится» редактором, архитектором решения или аналитиком рисков, он не меняет своей природы, но меняет правила выбора следующего шага, форму допустимых аргументов и формат продукта на выходе. Ролевое согласование — это коммуникативный контракт: мы не «просим помощи вообще», а задаём устройство взаимодействия, в котором понятен смысл каждого действия и способ проверки результата.
Наконец, о качестве моделей мира, с которыми мы входим в диалог. Модель не может привнести в общение онтологическую ясность, которой у нас нет: она может только усиливать или размывать уже заданный нами каркас. Поэтому работа с ЛЛМ — это, по сути, работа над собственной понятийной культурой. Чем точнее мы различаем типы объектов (системы, документы, протоколы), виды отношений (создание, использование, преобразование), типы ограничений (ресурсные, временные, регуляторные), тем устойчивее и продуктивнее совместное рассуждение. И наоборот, чем больше мы подменяем структуру риторикой — тем более риторическим будет и ответ.
Итог можно сформулировать так. Языковая модель — искусственный ассистент, который адаптирует своё поведение к уровню общения. Этот уровень задаётся не тоном и не «мотивацией», а онтологией разговора: точностью понятий, корректным разведением категорий, явными ролями, договорами о методах и требованиями к продуктам. Без этого сложные темы — математика, разработка продуктов, конструирование систем, саморазвитие — неизбежно распадутся на общие слова. С этим — становятся предметом профессионального диалога, где машина действительно помогает человеку думать и делать.