# Ключевые элементы взаимодействия с LLM: контекст, промпт, запрос

**Категория:** Блоги|Tseren Tserenov

**Дата:** 2025-07-16

**URL:** http://systemsworld.club/t/klyuchevye-elementy-vzaimodejstviya-s-llm-kontekst-prompt-zapros/28344/1

---

\*\*Введение\*\*
Эта архитектура реализует системный подход к организации персонального маршрута развития стажёра, основанного на методологии FPF, современных практиках prompt engineering и автоматической оптимизации входных данных (ADO). Её ядром является разделение трёх ключевых элементов Контекст, Промпт, Запрос:
\* Контекст: как состояние системы и базы данных, включающие public/private слой и оптимизированные по ADO.
\* Промпты: как инвариантные атомарные инструкции для LLM, жестко привязанные к ролям.
\* Запросы: как машинно-читаемые директивы, которые маршрутизируют и связывают Контекст и Промпт в единичной транзакции выполнения.
Стажёр в этой системе осваивает мета-понятия доменной зоны, структурированные и согласованные с универсальным набором мета-мета-понятий интеллект-стека. Это создаёт фундамент для трансдисциплинарной совместимости и бесшовной интеграции знаний.
На основе этого документа мы будем создавать [Проводника](https://systemsworld.club/t/opisanie-proekta-razrabotki-provodnika-po-personalnomu-marshrutu-razvitiya/25428) по персональному маршруту развития.
\*\*1. Контекст\*\*
Контекст — это агрегат знаний (`U.Episteme`), который собирается и оптимизируется Оркестратором перед передачей LLM-агенту. Он содержит два слоя:
\* Public-слой (`U.SharedEpisteme`):
\* Руководство по доменной зоне (разбитое на разделы) или структура руководства;
\* Понятия в графе, где связаны между собой мета-мета- и мета-понятия;
\* Справочные материалы (глоссарии, методические шпаргалки, вопросы на повторения или задачи).
Эти данные — неизменяемые, общедоступные, read-only и кэшируемые.
\* Private-слой (`U.PersonalizedEpisteme`):
\* Прогресс стажёра в освоении мета-понятий.
\* Оценки, комментарии наставников, результаты тестов.
\* История выполнения заданий, времени на упражнения.
Эти данные защищены, хранятся в шифрованном виде, передаются только по Secure Compute API, соответствуют требованиям GDPR/PDPA.
Контекст включает также понятийную структуру обучения:
\* Мета-мета-понятия — универсальные конструкты, определяющие логическую структуру.
\* Мета-понятия — доменные категории, привязанные к мета-мета-понятиям.
Перед подачей в LLM \*\*контекст может быть оптимизирован автоматически\*\* (ADO):
\* Content engineering: удаление нерелевантного, заполнение пропусков.
\* Structural reformulation: организация в форматах, которые LLM лучше обрабатывает (таблицы, иерархии, XML).
\*\*2. Промпт\*\*
Промпт (`U.MethodSpec`) — это неизменяемая текстовая инструкция, задающая метод выполнения конкретной роли LLM-агентом. Особенности промптов в этой архитектуре:
\* Один промпт = одна атомарная роль / функция Проводника.
\* Промпт всегда включает:
\* Определение роли LLM.
\* Задачу (Directive): что именно требуется сделать.
\* Алгоритм персонализации (по уровню стажёра, истории, карте понятий).
\* Описание формата ожидаемого результата (JSON, Markdown, patch для graph-db и др.).
\* Указание на работу с понятийной структурой (учёт мета-мета- и мета-понятий).
Каталог промптов обеспечивает:
\* Версионирование (prompt\\_id + версия \\_vN).
\* Трассируемость: каждый промпт фиксируется и может быть протестирован изолированно.
\* Независимость логики: изменение одного промпта не влияет на другие.
Все промпты разрабатываются с учётом:
\* Связи с двухуровневой онтологией понятий.
\* Прямого соответствия `U.MethodSpec` в FPF.
\* Возможности использования различных LLM-семейств под разные задачи.
\*\*3. Запрос\*\*
Запрос — это машинно-читаемая директива (`RequestObject`) от Оркестратора к LLM-агенту, которая объединяет ссылку на Контекст, ссылку на Промпт и параметры исполнения.
Ключевые поля запроса:
\* `role`: идентификатор роли, для которой исполняется запрос.
\* `prompt\_ref`: ссылка на версию промпта.
\* `context\_ref`: ссылка на собранный и оптимизированный Контекст.
\* `trainee\_id`: идентификатор стажёра.
\* `objective`: конкретная цель текущего вызова (например: подготовить задание для освоения мета-понятия N).
\* `trace\_id`: уникальный идентификатор для трассировки.
Запрос не является «вопросом пользователя» в привычном смысле — он выступает как "посыльный объект", соединяющий:
\* Статическую методологию (Промпт);
\* Динамические данные (Контекст);
\* Цель (`U.Objective`) конкретной итерации обучения.
\*\*4. Взаимодействие компонентов\*\*
Функциональная схема работы на примере выдачи ежедневного задания:
1️⃣ Оркестратор в 08:00 запускает цикл для стажёра X.
2️⃣ Формируется Контекст:
\* Public: актуальное руководство и карта понятий.
\* Private: прогресс X, история выполненных заданий.
\* Понятийная структура для стажёра, согласованная с мета-мета-понятиями.
\* Применяется ADO-оптимизация.
3️⃣ Выбирается Промпт для роли «Генератор персональных руководств».
4️⃣ Формируется Запрос:
\* `prompt\_ref`: PersonalGuideGenPrompt\\_v2.
\* `context\_ref`: собранный и оптимизированный Контекст.
\* `objective`: подготовить текст раздела руководства для X на сегодня.
\* `trace\_id`: фиксируется для трассировки.
5️⃣ LLM получает запрос, исполняет промпт с учётом контекста и возвращает результат в стандартизированном виде.
6️⃣ Оркестратор валидирует и сохраняет результат в `personal\_guides\_db`.
7️⃣ Новая запись становится частью обновлённого Контекста для следующих итераций.
\*\*5. Результаты этого разделения\*\*
\* Согласованность: каждая подсистема исполняет предсказуемую, изолированную, версионируемую логику.
\* Трассируемость: (prompt\\_ref, context\\_ref, trace\\_id) → output\\_hash → db\\_record.
\* Онтологическая совместимость: обучение ведётся по универсальной схеме согласования понятий.
\* Масштабируемость: добавление новой функции требует только новый промпт + новый маршрут в Оркестраторе, без изменения остальной архитектуры.
\_\_\_\_\_
Документы-источники. При создании данной схемы были проанализированы и использованы следующие ключевые документы и источники:
\* FPF Specification (full), 15.07.25
Подробная спецификация First Principles Framework (FPF) — «операционной системы для мышления». Документ описывает, зачем и как построена эта мегарама из модулей-фреймворков, какие у неё базовые понятия, правила, процессы развития и тестирования. Он нужен тем, кто хочет формально, машино-читаемо и при этом междисциплинарно описывать системы, знания, методы, ресурсы и цели.
\* Google Whitepaper: Prompt Engineering (2024)
Описывает практики проектирования промптов, включая system prompting, contextual prompting, role prompting и выбор конфигураций (temperature, top-K, top-P).
\* Automatic Data Optimization for Inputs in LLM Prompts (2025)
Научная работа, обосновывающая необходимость оптимизации данных до их включения в промпт (content engineering, structural reformulation), в том числе автоматическую оптимизацию input data как отдельный этап в pipeline.
\* The Prompt Report: A Systematic Survey of Prompt Engineering Techniques (2025, arXiv)
Полный обзор современной терминологии и классификации prompting techniques, включая разницу между «directive», «context», «examples» и «output formatting».
Эти источники обеспечили теоретическую и практическую основу для формулировки строгого и модульного разделения элементов архитектуры и уточнения терминологии.

---

Андрей, спасибо за анализ. Существенных замечаний не заметил, формулировки можно уточнить, но суть все кому надо итак понимают. Материал скорее для разработчиков.
Еще на будущее, пожалуйста, сокращайте текст в коммуникации. Например, не перекидывайте полный текст ответа ИИ, а выбирайте только суть, но если автор заинтересуется, тогда можно давать полный текст. По мере коммуникации текст может расти, но лучше сразу не кидаться простынями).